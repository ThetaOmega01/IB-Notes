\documentclass[a4paper]{article}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\triposcourse}{Linear Algebra}
\input{../header.tex}
\graphicspath{ {./images/} }
\pgfplotsset{compat=1.17}
\begin{document}
\maketitle
\tableofcontents
\newpage
\part*{Lecture 1}
\section{Vector Spaces}
\subsection{Vector spaces and subspaces}
Let $ \bbF $ be an arbitrary field ($ \mathbb{R}  $ or $ \mathbb{C}  $).

\begin{definition}[$ \bbF $ Vector Space]
    An \textit{$ \bbF$ vector space} (or a \textit{vector space over $\bbF$}) is a an abelian group $ (V,+) $ with a function $ \bbF\times V \mapsto V $, defined by $ (\lambda, \bfv) \mapsto \lambda\bfv $, such that 
    \begin{enumerate}
        \item $ \lambda(\bfv_1+\bfv_2)=\lambda\bfv_1+\lambda\bfv_2 $,
        \item $ (\lambda_1+\lambda_2)\bfv = \lambda_1\bfv+\lambda_2\bfv $,
        \item $ \lambda(\mu\bfv)=(\lambda\mu)\bfv $,
        \item $ 1\bfv=\bfv $,
    \end{enumerate}
    for all $ \lambda,\mu\in \bbF$ and $ \bfv\in V $.
\end{definition}

\begin{example}
    \begin{enumerate}
        \item $ \bbF^n,\ n\in \mathbb{N}  $ is a vector space.
        \item $ \bbR^X $, where $X$ is a set, is a vector space.
        \item $ \mcM_{n,m}(\bbF) $ is a vector space.
    \end{enumerate}
\end{example}
\begin{remark}
    The axioms imply that $ \forall \bfv\in V,\ 0\cdot\bfv=0 $.
\end{remark}

\begin{definition}[Subspace]
    Let $V$ be a vector space on $\bbF$. A subset $U$ of $V$ is a \textit{vector subspace} if 
    \begin{enumerate}
        \item $ \mathbf{0}\in U $,
        \item $ (\bfu_1,\bfu_2)\in U\times U \Rightarrow u_1+u_2\in U $,
        \item $ (\lambda,\bfu)\in \bbF\times U \Rightarrow \lambda\bfu\in U $.
    \end{enumerate}
    Equivalently, $U$ is a subspace of $V$ if 
    \[
        \forall (\lambda,\mu)\in \bbF\times \bbF,\ \forall (\bfu,\bfv)\in U\times U,\ \lambda\bfu+\mu\bfv\in U.
    \]
    Denote $ U\le V $.
\end{definition}
Recall from Vectors and Matrices: the two definitions are equivalent.
\begin{proposition}
    Let $ V $ be a vector space over $\bbF$. If $ U\le V $, then $U$ is a vector space over $\bbF$.
\end{proposition}
\begin{example}
    \begin{enumerate}
        \item $ \mathbb{P}(\bbR)\le \mcC(\bbR)\le \mathbb{R} ^\mathbb{R}  $.
        \item The set of vectors
        $$
        \left\{\begin{pmatrix}x_1 \\ x_2 \\ x_3\end{pmatrix} : x_1, x_2, x_3 \in \bbR, x_1 + x_2 + x_3 = t\right\}
        $$
        is a subspace of $\bbR^3$ for $t = 0$ only.
    \end{enumerate}
\end{example}
\begin{proposition}[Intersecting Subspaces]
    Let $U, W \le V$. Then $U \cap W \le V$.
\end{proposition}
\begin{proof}
    Since $0 \in U$ and $0 \in W$, we have $0 \in U \cap W$. Now if $\lambda_1, \lambda_2 \in \bbF$ and $\bfv_1, \bfv_2 \in U \cap W$, then $\lambda_1 \bfv_1 + \lambda_2 \bfv_2 \in U$ and $V$, and thus is in $U \cap V$. Thus $U \cap W \le V$.
\end{proof}
The union of two subspaces is generally \emph{not} a subspace, as it is typically not closed by addition. In fact, the union is only ever a subspace if one of the subspaces is contained in the other. 
\begin{center}
    \includegraphics[scale=0.13]{la1.jpeg}
\end{center}

\begin{definition}[Sum of vector spaces]
    Let $V$ be a vector space over $\bbF$ and let $U,W\le V$. The \textit{sum} of $U,W$ is defined as 
    \[
        U+W  =\left\{ \bfu+\bfw: (\bfu,\bfw)\in U\times W \right\}.
    \] 
\end{definition}
For example, the sum of $x$-axis and $y$-axis is $ \mathbb{R}^{2} $.

\begin{proposition}
    $U+W\le V$.
\end{proposition}
\begin{proposition}
    $U+W$ is the smallest subspace of $V$ that contains $U,W$.
\end{proposition}
\begin{proof}
    Let $X$ be a subspace of $V$ that contains $U,W$. By closure, $ \bfu+\bfw\in X $ for all $ \bfu\in U,\bfw\in W $, so $ U+W\le X $. Hence it is the smallest subspace.
\end{proof}
\subsection{Subspaces and quotient}
\begin{definition}[Quotient]
    Let $V$ a vector space over $\bbF$, and let $U \leq V$. The \emph{quotient space} $V/U$ is the abelian group $V/U$ equipped with the scalar multiplication $\bbF \times V/U \rightarrow V/U$, $(\lambda, \bfv + U) \mapsto \lambda \bfv + U$.
\end{definition}
The multiplication is well-defined, since if $ \bfv_1+U=\bfv_2+U $ then $ \bfv_1-\bfv_2\in U $, which implies $ \lambda(\bfv_1-\bfv_2) \in U$, and thus $ \lambda\bfv_1+U=\lambda\bfv_2+U\in V/U $.
\begin{proposition}
    $V/U$ is a vector space over $\bbF$.
\end{proposition}
\begin{proof}
    Let $ \lambda_1,\lambda_2\in \bbF $ and let $ \bfv_1+U,\bfv_2+U\in V/U $. Note that 
    \begin{align*}
        \lambda_1(\bfv_1+U)+\lambda_2(\bfv_2+U) &= (\lambda_1\bfv_1+U)+(\lambda_2\bfv_2+U)\\ 
        &= \lambda_1\bfv_1+\lambda_2\bfv_2+U\in V/U.\qedhere
    \end{align*}
\end{proof}
\newpage
\part*{Lecture 2}
\subsection{Spans, independence and Steinitz Exchange Lemma}
\begin{definition}[Span of a Family of Vectors]
    Let $V$ be a vector space over $\mathbb F$ and $S\subset V$.
    We define the span of $S$ to be
    $$\langle S\rangle=\operatorname{span}(S)=\left\{\sum_{i=1}^n\lambda_i\bfs_i:n\in\mathbb N,\lambda_i\in \mathbb F,\bfs_i\in S\right\}$$
\end{definition}
That is, $\langle S\rangle$ consists of all possible \textit{finite} linear combination of elements of $S$.
By convention, $\langle \varnothing\rangle=\{0\}$.
\begin{remark}
    $ \langle S \rangle  $ is the smallest vector subspace of $V$ which contains $S$.
\end{remark}
\begin{example}
    \begin{enumerate}
        \item $V=\mathbb{R}^{3}$,
        \[
            S = \left\{\begin{pmatrix}
                1 \\ 0 \\ 0
            \end{pmatrix}, \begin{pmatrix}
                0 \\ 1 \\ 2
            \end{pmatrix}, \begin{pmatrix}
                3 \\ -2 \\ -4
            \end{pmatrix}\right\}.
        \]
        Verify that 
        \[
            \langle S \rangle = \left\{ \begin{pmatrix}
                a \\ b \\ 2b
            \end{pmatrix}:(a,b)\in \mathbb{R} \right\}.
        \]
        \item $ V = \mathbb{R}^{n} $, $\bfe_i$ standard basis, then $ V = \langle (\bfe_i)_{1\le i\le n} \rangle  $.
        \item Let $V=\mathbb R^X$ and $\delta_x:X\to\mathbb R$ be such that $\delta_x(y)=1_{x=y}$.
        Then $\langle \{\delta_x\}_{x\in\mathbb R}\rangle$ are the set of functions $f\in\mathbb R^X$ that has finite support ($ \operatorname{Supp} f = \{x:f(x)\neq 0\} $).
    \end{enumerate}
\end{example}
\begin{definition}
    Let $V$ be a vector space over $\mathbb F$ and $S\subset V$.
    We say $S$ spans $V$ if $\langle S\rangle =V$.
\end{definition}
\begin{example}
    Take $V=\mathbb R^2$, then any set of two non-parallel vectors would span $V$.
\end{example}
\begin{definition}
    A vector space $V$ over $\mathbb F$ is finite dimensional if there is a finite $S\subset V$ that spans $V$.
\end{definition}
\begin{example}
    $V=\mathbb P[x]$, the set of polynomials in $\mathbb R$ and $V_n=\mathbb P_n[x]$, the set of real polynomials with degree $\le n$.
    Then $V_n=\langle\{1,x,\ldots,x^n\}\rangle$ is finite dimensional, but $V$ is not finite dimensional as any finite set of polynomials must be contained in $V_n$ where $n$ is the maximal degree of polynomials in that set.
\end{example}
If $V$ is finite-dimensional, is there a minimal number of vectors in the family required so that the family spans $V$?
\begin{definition}[(Linear) Independence]
    Let $V$ be a vector space over $F$.
    We say $\{\bfv_1,\ldots,\bfv_n\}\subset V$ are (linearly) independent (or is a free family) if for any $\lambda_1,\ldots,\lambda_n\in F$
    $$\sum_{i=1}^n\lambda_i\bfv_i=0\implies\forall i,\lambda_i=0$$
    Equivalently, this set is not linearly independent if there exists $\lambda_1,\ldots,\lambda_n\in F$ not all zero such that $\sum_{i=1}^n\lambda_i\bfv_i=0$.
\end{definition}
\begin{example}
Let $V=\mathbb R^3$ and
$$\bfv_1=(1,0,0)^\top,\bfv_2=(0,1,0)^\top,\bfv_3=(1,1,0)^\top,\bfv_4=(0,1,1)^\top$$
Then $\{\bfv_1,\bfv_2\}$ is linearly independent.
Note that $\bfv_3\in\langle\{\bfv_1,\bfv_2\}\rangle$, so $\{\bfv_1,\bfv_2,\bfv_3\}$ is not linearly independent.
On the other hand, $\bfv_4\notin\langle\{\bfv_1,\bfv_2\}\rangle$, which as one can verify means that $\{\bfv_1,\bfv_2,\bfv_4\}$ is linearly independent.
\end{example}
\begin{remark}
    If the family $\{\bfv_i\}_{1\le i\le n}$ is linearly independent, then none of $\bfv_i$ is zero.
\end{remark}
\begin{definition}[Basis]
    A subset $S\subset V$ is a basis if it is linearly independent and $\langle S\rangle=V$.
\end{definition}
\begin{remark}
    When $S$ spans $V$, we say that $S$ is a generating family of $V$.
    So a basis is just a linearly independent(we also say free) generating family.
\end{remark}
\begin{example}
    \begin{enumerate}
        \item Take $V=\mathbb R^n$, then the family $\{\bfe_i\}_{1\le i\le n}$ where $\bfe_i$ is the vector having $1$ at $i^{th}$ entry and zero otherwise is a basis. $ (\bfe_i) $ are called the \textit{canonical basis}.
        \item Take $V=\mathbb C$ over $\mathbb C$, then $\{a\}$ is a basis for any $a\neq 0$.
        \item Take also $V=\mathbb C$ but over $\mathbb R$, then $\{1,i\}$ is a basis.
        \item Take $V=\mathbb P[x]$ be the set of polynomials in $\mathbb R$ and $S=\{x^n:n\ge 0\}$.
        Then $S$ is a basis.
        Worth noting that $|S|=\infty$ in this case.
    \end{enumerate}
\end{example}
\begin{lemma}
    If $V$ is a vector space over $F$, then $\{\bfv_1,\ldots,\bfv_n\}$ is a basis of $V$ if and only if for any vector $\bfv\in V$, there is a unique decomposition
    $$\bfv=\sum_{i=1}^n\lambda_i\bfv_i,\quad \lambda_i\in \mathbb{F}.$$
\end{lemma}
\begin{remark}
    If the conditions are true, then the tuple $(\lambda_1,\ldots,\lambda_n)$ (ordered via the ordering one chose on $\bfv_i$) is called the coordinate of $\bfv$ in the basis $(\bfv_i)$.
\end{remark}
\begin{proof}
    Suppose $ (\bfv_i) $ is a basis of $V$. This implies that $ \langle \bfv_i \rangle =V $, i.e. 
    \[
        \forall \bfv\in V\quad \exists (\lambda_1,\dots,\lambda_n)\in \bbF,\quad \bfv = \sum_{i=1}^{n}\lambda_i\bfv_i.
    \]
    Suppose that $ \exists (\lambda_i') $ s.t. the above holds, then 
    \[
        \sum_{i=n}^{n} \lambda_i-\lambda'_i=0 \Longrightarrow \lambda_i=\lambda_i'
    \]
    by independence.

    Suppose now that there is a unique decomposition. Then clearly $ \langle (\bfv_i) \rangle =V $. Consider 
    \[
        \sum_{i=1}^n\lambda_i\bfv_i=0,\quad \lambda_i\in \mathbb{F}.
    \]
    Clearly it is true for $ \lambda_i=0,\forall i $. By uniqueness, this is the only decomposition and thus $ (\bfv_i) $ is a basis.
\end{proof}
\begin{lemma}
    If $S$ is a finite set that spans $V$, then a subset of $S$ is a basis of $V$.
\end{lemma}
\begin{proof}
    If $S$ is independent, then we are done.
    Otherwise, there is some $\lambda\neq 0$ and $\lambda_\bfw$ such that there is $v\in S$ with
    $$\lambda \bfv+\sum_{\bfw\in S\setminus\{\bfv\}}\lambda_\bfw\bfw=0\implies \bfv=\frac{1}{\lambda}\sum_{\bfw\in S\setminus\{\bfv\}}\lambda_\bfw\bfw\in\langle S\setminus\{\bfv\}\rangle.$$
    Therefore $S\setminus\{\bfv\}$ also spans $V$.
    We can repeat this process and, by the well-ordering of $\mathbb N$, will reach a basis.
\end{proof}
\begin{theorem}[Steinitz Exchange Lemma]\label{thm:steinitz}
    Let $V$ be a finite dimensional vector space over $\bbF$. Take $\{\bfv_1,\ldots,\bfv_m\}\subset V$ linearly independent, $\{\bfw_1,\ldots,\bfw_n\}\subset V$ a generating set, then:
    \begin{enumerate}
        \item $m\le n$.
        \item Up to relabeling, $\{\bfv_1,\ldots,\bfv_m,\bfw_{m+1},\ldots,\bfw_n\}$ spans $V$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    Suppose $\{\bfv_1,\ldots,\bfv_l,\bfw_{l+1},\ldots,\bfw_n\}$ spans $V$ for some $l<m$, then
    $$\exists\alpha_i,\beta_i\in \bbF, \bfv_{l+1}=\sum_{i\le l}\alpha_i\bfv_i+\sum_{i>l}\beta_i\bfw_i$$
    But $\{\bfv_i\}$ is linearly independent, so one of the $\beta_i$ is nonzero.
    By relabelling $\beta_{l+1}\neq 0$, then $\bfw_{l+1}\in\langle\{\bfv_1,\ldots,\bfv_l,\bfv_{l+1},\bfw_{l+2}\ldots,\bfw_n\}\rangle$, therefore the set of vectors $\{\bfv_1,\ldots,\bfv_l,\bfv_{l+1},\bfw_{l+2}\ldots,\bfw_n\}$ also spans $V$. If we start from 0, we are done after $m$ steps by induction, and thus $m\le n$, and
    \[
        \langle \bfv_1,\ldots,\bfv_m,\bfw_{m+1},\ldots,\bfw_n \rangle =V.\qedhere
    \]
\end{proof}
\end{document}